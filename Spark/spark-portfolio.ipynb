{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03908c2f-4bfb-48ac-8a55-59dc2f28ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json,window, to_timestamp, when, count, avg, max, min,to_json,struct\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.streaming import StreamingQueryException\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StructuredStreamingWithKafka\") \\\n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e02fde-afee-4446-b797-38aacd3f71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_df = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"host.docker.internal:29092\")\n",
    "    .option(\"subscribe\", \"logging_info\")\n",
    "    .option(\"startingOffsets\", \"latest\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf15708-da21-438a-ada7-ee7fdcf98419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a3b5817-8eaa-4d2a-aae7-8b7b0c05fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"timestamp\", LongType(), True),  # Numeric timestamp in milliseconds\n",
    "    StructField(\"api\", StringType(), True),\n",
    "    StructField(\"response_time\", IntegerType(), True),\n",
    "    StructField(\"log_level\", StringType(), True),\n",
    "    StructField(\"ip_address\", StringType(), True),\n",
    "    StructField(\"status_code\", StringType(), True),\n",
    "    StructField(\"response_code\", IntegerType(), True),\n",
    "    StructField(\"timestamp_human\", StringType(), True)  # String timestamp\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc546519-99ee-495b-b684-8703c591fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_parsed = kafka_df.select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"log\")).select(\"log.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c54b387-f8d9-433f-8145-27e567949c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_parsed = log_data_parsed.withColumn(\n",
    "    \"timestamp_converted\", \n",
    "    (col(\"timestamp\") / 1000).cast(\"timestamp\")  # Convert milliseconds to seconds, then cast to TIMESTAMP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40b6d675-6185-4ae3-aaf5-68cbfb20b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_parsed = log_data_parsed.withColumn(\n",
    "    \"timestamp\", \n",
    "    when(col(\"timestamp_converted\").isNotNull(), col(\"timestamp_converted\"))\n",
    "    .otherwise(to_timestamp(col(\"timestamp_human\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c97c3ae2-aa07-4395-a378-0e59c6a47057",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_parsed = log_data_parsed.drop(\"timestamp_converted\", \"timestamp_human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63f219ca-d5fd-4a35-8bd9-8a046decb616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- api: string (nullable = true)\n",
      " |-- response_time: integer (nullable = true)\n",
      " |-- log_level: string (nullable = true)\n",
      " |-- ip_address: string (nullable = true)\n",
      " |-- status_code: string (nullable = true)\n",
      " |-- response_code: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_data_parsed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7987c5df-d364-4edc-8253-71de3ca881e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate logs by minute, including watermarking\n",
    "minute_aggregates = (\n",
    "    log_data_parsed\n",
    "    .withWatermark(\"timestamp\", \"1 minute\")  # Handle late-arriving data\n",
    "    .groupBy(\n",
    "        window(col(\"timestamp\"), \"1 minute\").alias(\"minute_window\"),  # Group by 1-minute window\n",
    "        \"api\",\n",
    "        \"log_level\"\n",
    "    )\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"log_count\"),\n",
    "        avg(\"response_time\").alias(\"avg_response_time\"),\n",
    "        max(\"response_time\").alias(\"max_response_time\"),\n",
    "        min(\"response_time\").alias(\"min_response_time\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Correctly reference window start and end from the window struct\n",
    "minute_aggregates_stream = minute_aggregates.select(\n",
    "    col(\"minute_window.start\").alias(\"window_start\"),  # Access window start field\n",
    "    col(\"minute_window.end\").alias(\"window_end\"),  # Access window end field\n",
    "    \"api\",\n",
    "    \"log_level\",\n",
    "    \"log_count\",\n",
    "    \"avg_response_time\",\n",
    "    \"max_response_time\",\n",
    "    \"min_response_time\"\n",
    ")\n",
    "\n",
    "# Convert the DataFrame to JSON format for Kafka\n",
    "minute_aggregates_stream_json = minute_aggregates_stream.select(\n",
    "    to_json(struct('window_start', 'window_end', 'api', 'log_level', \n",
    "                  'log_count', 'avg_response_time', \n",
    "                  'max_response_time', 'min_response_time')).alias('value')\n",
    ")\n",
    "checkpoint_path = \"./tmp/checkpoints\"\n",
    "\n",
    "minute_aggregates_stream_json.printSchema()\n",
    "query = minute_aggregates_stream_json \\\n",
    "        .writeStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"host.docker.internal:29092\")\\\n",
    "        .option(\"topic\", \"agg_logging_info\") \\\n",
    "        .option(\"checkpointLocation\", checkpoint_path)\\\n",
    "        .outputMode(\"append\").start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
